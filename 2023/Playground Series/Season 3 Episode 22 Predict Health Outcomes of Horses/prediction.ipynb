{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des outils / jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from column_names import (\n",
    "    id_col,\n",
    "    quali_var,\n",
    "    quali_var_binary,\n",
    "    quali_var_for_ohe,\n",
    "    quanti_var,\n",
    "    target,\n",
    ")\n",
    "from prediction import (\n",
    "    create_models,\n",
    "    create_x_pipeline,\n",
    "    evaluate_models,\n",
    "    make_prediction,\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "np.random.seed(SEED)\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(\"data/original_dataset_train.csv\")\n",
    "df = pd.read_csv(\"data/train.csv\", index_col=id_col)\n",
    "X_kaggle = pd.read_csv(\"data/test.csv\", index_col=id_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[quanti_var + quali_var].copy()\n",
    "y = df[target].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original_data = original_data[quanti_var + quali_var].copy()\n",
    "y_original_data = original_data[target].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liste des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = create_models(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Scaler & OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = create_x_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouveau_df = pd.DataFrame(\n",
    "    preprocessor.fit_transform(X),\n",
    "    index=df.index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor.named_steps['features_union'].transformer_list[1][1].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1235, 71)"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouveau_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "299"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_original_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouveau_X_original_data = pd.DataFrame(\n",
    "    preprocessor.transform(X_original_data),\n",
    "    index=X_original_data.index,\n",
    "    # columns=preprocessor.get_feature_names_out(),\n",
    ")\n",
    "y_encoded_original_data = le.transform(y_original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    nouveau_df, y, test_size=0.2, random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_original_data = pd.concat((X_train, nouveau_X_original_data))\n",
    "y_train_with_original_data = np.hstack((y_train, y_encoded_original_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (988, 71)\n",
      "y_train.shape = (988,)\n",
      "X_train_with_original_data.shape = (1287, 71)\n",
      "y_train_with_original_data.shape = (1287,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X_train.shape = }\")\n",
    "print(f\"{y_train.shape = }\")\n",
    "print(f\"{X_train_with_original_data.shape = }\")\n",
    "print(f\"{y_train_with_original_data.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_with_original_data\n",
    "y_train = y_train_with_original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "défaut/DummyClassifier_Uniform\n",
      "défaut/DummyClassifier_MostFrequent\n",
      "défaut/LGBMClassifier\n"
     ]
    }
   ],
   "source": [
    "prefix = \"défaut\"\n",
    "results = evaluate_models(models, prefix, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[['défaut/LGBMClassifier', 0.7280826065891473, 0.04706282329868854],\n ['défaut/DummyClassifier_MostFrequent',\n  0.49416787790697675,\n  0.0026137333854799978],\n ['défaut/DummyClassifier_Uniform', 0.36982800387596904, 0.027225387160455063]]"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soumission Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models[\"LGBMClassifier\"]\n",
    "submission_name = \"original_data4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_predictions = make_prediction(\n",
    "    best_model, X_train, y_train, X_kaggle, preprocessor, le\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_predictions.to_csv(f\"data/results/{submission_name}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
